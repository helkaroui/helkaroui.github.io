"use strict";(self.webpackChunksharek_dev=self.webpackChunksharek_dev||[]).push([[4891],{5680:(e,a,t)=>{t.d(a,{xA:()=>p,yg:()=>m});var r=t(6540);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function s(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);a&&(r=r.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,r)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?s(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,r,n=function(e,a){if(null==e)return{};var t,r,n={},s=Object.keys(e);for(r=0;r<s.length;r++)t=s[r],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)t=s[r],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var l=r.createContext({}),c=function(e){var a=r.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},p=function(e){var a=c(e.components);return r.createElement(l.Provider,{value:a},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return r.createElement(r.Fragment,{},a)}},g=r.forwardRef((function(e,a){var t=e.components,n=e.mdxType,s=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),d=c(t),g=n,m=d["".concat(l,".").concat(g)]||d[g]||u[g]||s;return t?r.createElement(m,o(o({ref:a},p),{},{components:t})):r.createElement(m,o({ref:a},p))}));function m(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var s=t.length,o=new Array(s);o[0]=g;var i={};for(var l in a)hasOwnProperty.call(a,l)&&(i[l]=a[l]);i.originalType=e,i[d]="string"==typeof e?e:n,o[1]=i;for(var c=2;c<s;c++)o[c]=t[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,t)}g.displayName="MDXCreateElement"},6725:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>c});var r=t(8168),n=(t(6540),t(5680));const s={title:"Strongly Typed Joins"},o=void 0,i={unversionedId:"spark/tools/strongly-typed-joins",id:"spark/tools/strongly-typed-joins",title:"Strongly Typed Joins",description:"When I discovered Spark,I was a fresh graduate looking for a data scientist position, with a limited knowledge of Python programming language and a love for machine learning libraries. So basically, my first interaction with Spark was throught PySpark : RDDs and DataFrames.",source:"@site/sections/data_processing/spark/05-tools/strongly-typed-joins.md",sourceDirName:"spark/05-tools",slug:"/spark/tools/strongly-typed-joins",permalink:"/data_processing/spark/tools/strongly-typed-joins",draft:!1,tags:[],version:"current",frontMatter:{title:"Strongly Typed Joins"},sidebar:"docs",previous:{title:"Sparking Creativity: A Friendly Guide to Extending Spark UI",permalink:"/data_processing/spark/customization/extend-spark-ui"},next:{title:"Databricks Certified Associate Developer for Apache Spark Exam questions",permalink:"/data_processing/spark/articles/databricks-spark-developer-associate-exam"}},l={},c=[{value:"Background",id:"background",level:2},{value:"Introducing Scala-meta &amp; macros",id:"introducing-scala-meta--macros",level:2},{value:"Scala macros",id:"scala-macros",level:3},{value:"Scala-meta",id:"scala-meta",level:3},{value:"Get Fields from case class",id:"get-fields-from-case-class",level:2},{value:"Wrap things up",id:"wrap-things-up",level:2},{value:"Conclusion",id:"conclusion",level:2}],p={toc:c},d="wrapper";function u(e){let{components:a,...t}=e;return(0,n.yg)(d,(0,r.A)({},p,t,{components:a,mdxType:"MDXLayout"}),(0,n.yg)("p",null,"When I discovered Spark,I was a fresh graduate looking for a data scientist position, with a limited knowledge of Python programming language and a love for machine learning libraries. So basically, my first interaction with Spark was throught PySpark : RDDs and DataFrames. "),(0,n.yg)("p",null,"And it was until I land my first consultant job, that I discovered Scala, and I felt in love. Anyway, since then, I have been working with Dataset API, and that lead to fewer RUNTIME errors, since most of the coding errors were illiminated thanks to the compiler."),(0,n.yg)("p",null,"Except for one thing, Joins !\nto code join conditions in scala, one should pass the field name as a string :"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-scala"},'salesDs\n    .joinWith(customerDs, salesDs("clientId") === customerDs("id"), "left")\n')),(0,n.yg)("p",null,"In this article, I'll describe how I solved the typing issue in join conditions, and came up with a strongly typed join condition in Spark."),(0,n.yg)("p",null,"Here is how the typed join condition looks like :"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-scala"},'salesDs\n    .joinWith(customerDs, salesDs.fields.clientId === customerDs.fields.id, "left")\n')),(0,n.yg)("h2",{id:"background"},"Background"),(0,n.yg)("p",null,"TBD"),(0,n.yg)("h2",{id:"introducing-scala-meta--macros"},"Introducing Scala-meta & macros"),(0,n.yg)("h3",{id:"scala-macros"},"Scala macros"),(0,n.yg)("p",null,"TBD"),(0,n.yg)("h3",{id:"scala-meta"},"Scala-meta"),(0,n.yg)("p",null,"Scalameta has syntax trees that represent Scala programs.\nSyntax trees are a representation of source code that makes it easier to programmatically analyze programs\nScalameta trees are lossless, meaning that they represent Scala programs in sufficient detail to go from text to trees and vice-versa."),(0,n.yg)("h2",{id:"get-fields-from-case-class"},"Get Fields from case class"),(0,n.yg)("p",null,"TBD"),(0,n.yg)("h2",{id:"wrap-things-up"},"Wrap things up"),(0,n.yg)("p",null,"TBD"),(0,n.yg)("h2",{id:"conclusion"},"Conclusion"),(0,n.yg)("p",null,"Resources :"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://github.com/lorandszakacs/field-names"},"https://github.com/lorandszakacs/field-names"))),(0,n.yg)("p",null,"Example for Idea plugin :\n",(0,n.yg)("a",{parentName:"p",href:"https://github.com/shadaj/slinky/blob/main/coreIntellijSupport/build.sbt"},"https://github.com/shadaj/slinky/blob/main/coreIntellijSupport/build.sbt")),(0,n.yg)("p",null,"Answer on gitter :\n",(0,n.yg)("a",{parentName:"p",href:"https://gitter.im/JetBrains/intellij-scala?at=5dca8885add5717a88f332f8"},"https://gitter.im/JetBrains/intellij-scala?at=5dca8885add5717a88f332f8")),(0,n.yg)("p",null,"How to create Macro support for Idea\n",(0,n.yg)("a",{parentName:"p",href:"https://blog.jetbrains.com/scala/2015/10/14/intellij-api-to-build-scala-macros-support/"},"https://blog.jetbrains.com/scala/2015/10/14/intellij-api-to-build-scala-macros-support/")),(0,n.yg)("p",null,"Why not create a compiler plugin like scalapb\n",(0,n.yg)("a",{parentName:"p",href:"https://github.com/scalapb/ScalaPB/tree/master/compiler-plugin/src/main/scala/scalapb"},"https://github.com/scalapb/ScalaPB/tree/master/compiler-plugin/src/main/scala/scalapb")))}u.isMDXComponent=!0}}]);