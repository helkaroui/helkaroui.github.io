"use strict";(self.webpackChunksharek_dev=self.webpackChunksharek_dev||[]).push([[1841],{9784:e=>{e.exports=JSON.parse('{"pluginId":"data_processing","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"category","label":"Apache Spark","collapsed":true,"items":[{"type":"link","label":"Quick Start","href":"/data_processing/spark/","docId":"spark/index"},{"type":"category","label":"Internals","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/data_processing/spark/internals/index","docId":"spark/internals/index"},{"type":"link","label":"Plugin Framework","href":"/data_processing/spark/internals/plugin-framework","docId":"spark/internals/plugin-framework"}]},{"type":"category","label":"Customizations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Create a Spark plugin","href":"/data_processing/spark/customization/create-plugin","docId":"spark/customization/create-plugin"}]},{"type":"category","label":"Tutorials","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quick Start Guide to Apache Spark","href":"/data_processing/spark/tutorials/getting-started-with-spark","docId":"spark/tutorials/getting-started-with-spark"},{"type":"link","label":"Host your own Spark cluster","href":"/data_processing/spark/tutorials/setup_standalone_cluster","docId":"spark/tutorials/setup_standalone_cluster"}]},{"type":"category","label":"articles","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Exploring the Exciting New Features in Apache Spark 3.0","href":"/data_processing/spark/articles/whats-new-in-spark3","docId":"spark/articles/whats-new-in-spark3"}]},{"type":"category","label":"Optimizations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quick wins","href":"/data_processing/spark/02.5-optimizations/quick_wins","docId":"spark/02.5-optimizations/quick_wins"},{"type":"link","label":"ReduceByKey vs GroupByKey","href":"/data_processing/spark/02.5-optimizations/reducebykey_vs_groupbykey","docId":"spark/02.5-optimizations/reducebykey_vs_groupbykey"}]}],"collapsible":true},{"type":"category","label":"Kafka","collapsed":true,"items":[{"type":"link","label":"Quick Start","href":"/data_processing/kafka/","docId":"kafka/index"},{"type":"link","label":"Best practices","href":"/data_processing/kafka/best_practices","docId":"kafka/best_practices"},{"type":"link","label":"Cheat Sheet","href":"/data_processing/kafka/cheat_sheet","docId":"kafka/cheat_sheet"}],"collapsible":true}]},"docs":{"kafka/best_practices":{"id":"kafka/best_practices","title":"Best practices","description":"TBC","sidebar":"docs"},"kafka/cheat_sheet":{"id":"kafka/cheat_sheet","title":"Cheat Sheet","description":"You can create a new Kafka topic named my-topic as follows:","sidebar":"docs"},"kafka/index":{"id":"kafka/index","title":"Quick Start","description":"Introduction","sidebar":"docs"},"spark/02.5-optimizations/quick_wins":{"id":"spark/02.5-optimizations/quick_wins","title":"Quick wins","description":"Here are simple rules to follow to avoid crashing your spark job :","sidebar":"docs"},"spark/02.5-optimizations/reducebykey_vs_groupbykey":{"id":"spark/02.5-optimizations/reducebykey_vs_groupbykey","title":"ReduceByKey vs GroupByKey","description":"In this article we are demystifying two known Spark Operators: reduceByKey and groupByKey","sidebar":"docs"},"spark/articles/whats-new-in-spark3":{"id":"spark/articles/whats-new-in-spark3","title":"Exploring the Exciting New Features in Apache Spark 3.0","description":"Exploring the Exciting New Features in Apache Spark 3.0","sidebar":"docs"},"spark/customization/create-plugin":{"id":"spark/customization/create-plugin","title":"Create a Spark plugin","description":"Extend Spark with custom plugin","sidebar":"docs"},"spark/index":{"id":"spark/index","title":"Quick Start","description":"Apache Spark is an open-source distributed computing framework designed for processing and analyzing large-scale datasets in a fast and efficient manner. It was developed at the AMPLab at UC Berkeley and later donated to the Apache Software Foundation, where it became an Apache project. Spark is designed to provide a unified platform for various data processing tasks, including batch processing, real-time stream processing, machine learning, and interactive query analysis.","sidebar":"docs"},"spark/internals/index":{"id":"spark/internals/index","title":"Overview","description":"Most Spark developers ignores the hidden beast that is Spark. In this section, I collected some articles demystifying","sidebar":"docs"},"spark/internals/plugin-framework":{"id":"spark/internals/plugin-framework","title":"Plugin Framework","description":"Explore the internals of Spark\'s Plugin Framework","sidebar":"docs"},"spark/tutorials/getting-started-with-spark":{"id":"spark/tutorials/getting-started-with-spark","title":"Quick Start Guide to Apache Spark","description":"the guide serves as an excellent starting point for individuals interested in working with Apache Spark. It covers key aspects of installation, setup, and application development, encouraging readers to explore the extensive capabilities of Spark\'s libraries and features.","sidebar":"docs"},"spark/tutorials/setup_standalone_cluster":{"id":"spark/tutorials/setup_standalone_cluster","title":"Host your own Spark cluster","description":"In this article we will go through the steps of deploying a standalone Spark cluster on a bunch of virtual machines.","sidebar":"docs"}}}')}}]);