"use strict";(self.webpackChunksharek_dev=self.webpackChunksharek_dev||[]).push([[4287],{3905:function(e,t,r){r.d(t,{Zo:function(){return u},kt:function(){return d}});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),c=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},u=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=c(r),d=a,f=m["".concat(s,".").concat(d)]||m[d]||p[d]||o;return r?n.createElement(f,i(i({ref:t},u),{},{components:r})):n.createElement(f,i({ref:t},u))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=r[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},1832:function(e,t,r){r.r(t),r.d(t,{assets:function(){return u},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return l},metadata:function(){return c},toc:function(){return p}});var n=r(7462),a=r(3366),o=(r(7294),r(3905)),i=["components"],l={title:"Create a Spark plugin"},s=void 0,c={unversionedId:"spark/customization/create-plugin",id:"spark/customization/create-plugin",title:"Create a Spark plugin",description:"Spark Plugin Framework",source:"@site/sections/data_processing/spark/03-customization/create-plugin.md",sourceDirName:"spark/03-customization",slug:"/spark/customization/create-plugin",permalink:"/data_processing/spark/customization/create-plugin",draft:!1,tags:[],version:"current",frontMatter:{title:"Create a Spark plugin"},sidebar:"docs",previous:{title:"Plugin Framework",permalink:"/data_processing/spark/internals/plugin-framework"},next:{title:"Host your own Spark cluster",permalink:"/data_processing/spark/tutorials/setup_standalone_cluster"}},u={},p=[{value:"Spark Plugin Framework",id:"spark-plugin-framework",level:2},{value:"Features :",id:"features-",level:2},{value:"Internals :",id:"internals-",level:2},{value:"Simple Plugin",id:"simple-plugin",level:3},{value:"Metrics Connector",id:"metrics-connector",level:3},{value:"Custom Metrics UI Tab",id:"custom-metrics-ui-tab",level:3},{value:"Control Spark Streaming Application",id:"control-spark-streaming-application",level:3}],m={toc:p};function d(e){var t=e.components,r=(0,a.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"spark-plugin-framework"},"Spark Plugin Framework"),(0,o.kt)("p",null,"It was introduced in Spark 3.0.\nThis plugin allows users to plug custom code to the driver or/and worker instances at start time. This allows customization to be fairly simple and straightforward. It allows to have custom metrics tracking and more control over the Spark application."),(0,o.kt)("h2",{id:"features-"},"Features :"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Access to the Spark Context"),"\nSpark plugin gives access to the Spark Context instance and thus a way in to application metrics.\n",(0,o.kt)("strong",{parentName:"p"},"Ability to Communicate Between Driver and Executor"),"\nSpark plugin framework exposes a RPC communication option between driver and executor plugins. This communication can be used to send any user defined messages between executors and driver.\n",(0,o.kt)("strong",{parentName:"p"},"Ability to push dynamic events to driver and executor"),"\nSpark plugin framework allows user to run arbitrary listeners on driver or executor side. This allows for a communication to spark JVM\u2019s from the external application. As these plugins have access to spark context, this will allow for dynamic control of the execution from outside which is very powerful."),(0,o.kt)("h2",{id:"internals-"},"Internals :"),(0,o.kt)("p",null,"To understand the internals Plugin Framework, see this ",(0,o.kt)("a",{parentName:"p",href:"./../02-internals/plugin-framework.md"},"article")),(0,o.kt)("h3",{id:"simple-plugin"},"Simple Plugin"),(0,o.kt)("p",null,"TBC"),(0,o.kt)("h3",{id:"metrics-connector"},"Metrics Connector"),(0,o.kt)("p",null,"TBC"),(0,o.kt)("h3",{id:"custom-metrics-ui-tab"},"Custom Metrics UI Tab"),(0,o.kt)("p",null,"TBC"),(0,o.kt)("h3",{id:"control-spark-streaming-application"},"Control Spark Streaming Application"),(0,o.kt)("p",null,"TBC"))}d.isMDXComponent=!0}}]);