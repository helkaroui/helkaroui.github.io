---
title: 02-Hardening Nginx Security
---

import useBaseUrl from '@docusaurus/useBaseUrl';

Nginx is a lightweight, high-performance web server/reverse proxy and e-mail (IMAP/POP3) proxy. According to Netcraft,
13.50% of all domains on the Internet use nginx web server. Nginx is one of a handful of servers written to address the
C10K problem. Unlike traditional servers, Nginx doesn’t rely on threads to handle requests. Instead, it uses a much more
scalable event-driven (asynchronous) architecture. Nginx powers several high traffic web sites, such as WordPress, Hulu,
Github, and SourceForge.

This page collects hints how to improve the security of nginx web servers running on Linux operating system.

## #1 Use restrictive Iptables Based Firewall

The following firewall script blocks everything and only allows:

- Incoming HTTP (TCP port 80) requests
- Incoming HTTPS (TCP port 443) requests
- Incoming ICMP ping requests

In this tutorial we will use UFW to manage Iptables:
:::important

UFW is a simplified command line configuration tool from Netfilter, which provides an alternative to the iptables
tool. UFW should eventually allow automatic configuration of the firewall when installing programs that need it.

check if UFW is enabled on your system :
```shell
sudo ufw status
```

If UFW is down you can enable it by running this command:
```shell
sudo ufw enable
```

:::

To see the firewall current status, we will run the following command with verbose enabled :
```shell
sudo ufw status verbose
```
```text
Status: active
Logging: on (low)
Default: deny (incoming), allow (outgoing), deny (routed)
New profiles: skip

To                         Action      From
--                         ------      ----
80                         ALLOW IN    192.168.0.0/24
```
Here we have only one rule; and it's instructing our firewall to only accept incoming connection on port 53.

So, now want to allow incoming connections on the following ports: `80, 443`
```shell title="Allowing important ports"
sudo ufw allow 80
sudo ufw allow 443
```

Then we need to instruct the firewall to deny anything else :
```shell
sudo ufw default deny
```

Another recommended practice is to enable logging and send it to a monitoring tool like ELK or Promotheus
```shell title="Enable logging"
sudo ufw logging on
```

Logs will be written to `/var/log/ufw.log`
:::info

If you run out of disk space, think to install a log curator or just run the following commands :
```shell
sudo ufw logging off
sudo ufw logging low
```

:::


#### Debugging:
You should be aware that if your application should make outgoing call, you need to allow outgoing DNS queries.
This is done by running this command:
```shell
sudo ufw allow out 53
```



## #2: Controlling Buffer Overflow Attacks
Edit nginx.conf and set the buffer size limitations for all clients.
```text title="Edit /etc/nginx/nginx.conf"
 ## Start: Size Limits & Buffer Overflows ##
  client_body_buffer_size  1K;
  client_header_buffer_size 1k;
  client_max_body_size 1k;
  large_client_header_buffers 2 1k;
 ## END: Size Limits & Buffer Overflows ##
```
<br/>

Where,
- `client_body_buffer_size 1k` – (default is 8k or 16k) The directive specifies the client request body buffer size.
- `client_header_buffer_size 1k` – Directive sets the headerbuffer size for the request header from client. For the overwhelming majority of requests a buffer size of 1K is sufficient. Increase this if you have a custom header or a large cookie sent from the client (e.g., wap client).
- `client_max_body_size 1k`– Directive assigns the maximum accepted body size of client request, indicated by the line Content-Length in the header of request. If size is greater the given one, then the client gets the error “Request Entity Too Large” (413). Increase this when you are getting file uploads via the POST method.
- `large_client_header_buffers 2 1k` – Directive assigns the maximum number and size of buffers for large headers to read from client request. By default the size of one buffer is equal to the size of page, depending on platform this either 4K or 8K, if at the end of working request connection converts to state keep-alive, then these buffers are freed. 2x1k will accept 2kB data URI. This will also help combat bad bots and DoS attacks.

You also need to control timeouts to improve server performance and cut clients. Edit it as follows:
```text title="Edit /etc/nginx/nginx.conf"
## Start: Timeouts ##
  client_body_timeout   10;
  client_header_timeout 10;
  keepalive_timeout     5 5;
  send_timeout          10;
## End: Timeouts ##
```


- `client_body_timeout 10;` – Directive sets the read timeout for the request body from client. The timeout is set only if a body is not get in one readstep. If after this time the client send nothing, nginx returns error “Request time out” (408). The default is 60.
- `client_header_timeout 10;` – Directive assigns timeout with reading of the title of the request of client. The timeout is set only if a header is not get in one readstep. If after this time the client send nothing, nginx returns error “Request time out” (408).
- `keepalive_timeout 5 5;` – The first parameter assigns the timeout for keep-alive connections with the client. The server will close connections after this time. The optional second parameter assigns the time value in the header Keep-Alive: timeout=time of the response. This header can convince some browsers to close the connection, so that the server does not have to. Without this parameter, nginx does not send a Keep-Alive header (though this is not what makes a connection “keep-alive”).
- `send_timeout 10;` – Directive assigns response timeout to client. Timeout is established not on entire transfer of answer, but only between two operations of reading, if after this time client will take nothing, then nginx is shutting down the connection.


## #3: Control Simultaneous Connections

You can use NginxHttpLimitZone module to limit the number of simultaneous connections for the assigned session or as a
special case, from one IP address. Add the following lines:
```text title="Edit /etc/nginx/nginx.conf"
### Directive describes the zone, in which the session states are stored i.e. store in slimits. ###
### 1m can handle 32000 sessions with 32 bytes/session, set to 5m x 32000 session ###
       limit_zone slimits $binary_remote_addr 5m;

### Control maximum number of simultaneous connections for one session i.e. ###
### restricts the amount of connections from a single ip address ###
        limit_conn slimits 5;
```

The above will limits remote clients to no more than 5 concurrently “open” connections per remote ip address.

## #4: Allow Access To Our Domain Only
If bot is just making random server scan for all domains, just deny it. You must only allow configured virtual domain or
reverse proxy requests. You don’t want to display request using an IP address. Add the following lines at the end of the
config file:

```shell title="Edit /etc/nginx/nginx.conf"
## Only requests to our sites are allowed
http {
    ...
    server {
        listen      80 default_server;
        server_name _;
        return      444; # "Connection closed without response"
    }
}
##
```

## #5: Deny Certain User-Agents
You can easily block user-agents i.e. scanners, bots, and spammers who may be abusing your server.
```text title="Edit /etc/nginx/nginx.conf"
## Block download agents ##
     if ($http_user_agent ~* LWP::Simple|BBBike|wget) {
            return 444;
     }
##
```

For testing:
```shell
curl --head -A "wget" https://www.sharek.dev/
```
:::info

**What is http status 444 ?**
A non-standard status code used to instruct nginx to close the connection without sending a response to the client, most
commonly used to deny malicious or malformed requests.

:::

## #6: Only allow SSL requests
The first step in web security is to implement SSL so that you can access web applications with https and add a layer of
encryption in the communication.

```text
server {
  listen 80;
  server_name sharek.dev;
  return 301 https://$host$request_uri;
}

server {
    listen	443 ssl;
    server_name               sharek.dev;

    ssl_certificate     /path/to/certs/cert.pem;
    ssl_certificate_key /path/to/certs/privkey.pem;

    index                     index.html index.htm index.php;
    root                      /var/www/html;
}
```


Having SSL does not mean it is fully secure and this is where as a web security expert you need to apply some
configuration to secure the web server.

To start with, we recommend running an SSL scan against the website to find the score and the critical vulnerability.
Here is a well known online tool [SSLLabs](https://www.ssllabs.com/ssltest/index.html)

<img alt="Docusaurus with Keytar" src={useBaseUrl('/img/notes.home_cloud_notes.tutorials.01-ssllabs-report-01.png')} />

With our current setup, we've scored a B rating ! Nice, but if we want to push it further we need to apply some technics
found in this article: https://geekflare.com/fr/nginx-webserver-security-hardening-guide/

TBC

## #7: Disable server banner
In the default NGINX configuration, the server header banner is ON which exposes the version of Nginx you are using.
This is particularly considered as information leak, coz it helps the attacker to identify you server version and hence
target it's known vulnerabilities.
You can disable server banner with the following line :
```text title="Edit /etc/nginx/nginx.conf"
server_tokens off;
```

Now, check the response headers of a simple get request :
```shell
curl -I http://sharek.dev
```

If this configuration is not get you will see the following output:
```text {2}
HTTP/1.1 301 Moved Permanently
Server: nginx/1.18.0 (Ubuntu)
Date: Wed, 07 Apr 2021 13:52:15 GMT
Content-Type: text/html
Content-Length: 178
Connection: keep-alive
Location: https://sharek.dev/
```

## #8: Clickjacking attack
You can inject X-FRAME-OPTIONS in the HTTP header to prevent a clickjacking attack.
::::info

is a malicious technique of tricking a user into clicking on something different from what the user perceives, thus
potentially revealing confidential information or allowing others to take control of their computer while clicking on
seemingly innocuous objects, including web pages

::::

```text title="Edit /etc/nginx/nginx.conf"
add_header X-Frame-Options "SAMEORIGIN";
```
The above header will instruct a browser to load resources ONLY from the same origin.
Now, check the response headers of a simple get request :
```shell
curl -I http://sharek.dev
```
```text {7}
HTTP/1.1 301 Moved Permanently
Date: Wed, 07 Apr 2021 13:52:15 GMT
Content-Type: text/html
Content-Length: 178
Connection: keep-alive
Location: https://sharek.dev/
X-Frame-Options: SAMEORIGIN
```

## #9: X-XSS Protection
Inject an HTTP header with X-XSS protection to mitigate cross-site scripting attacks.

::::Info

Cross-site scripting (XSS) is a security exploit which allows an attacker to inject into a website malicious client-side
code. This code is executed by the victims and lets the attackers bypass access controls and impersonate users.

::::

```text title="Edit /etc/nginx/nginx.conf"
add_header X-XSS-Protection "1; mode=block";
```

## #10: Disable older SSL protocols in the Nginx configuration.
By default, Nginx installs with several older SSL protocols exposed, which could lead to a BEAST (Browser Exploit
Against SSL/TLS) attack. Older protocols should therefore be disabled for a better security posture. This can be
accomplished by defining the Nginx protocols/ciphers in your web server setting to only accept the newer, more secure
protocols.

```text {5} title="Edit /etc/nginx/nginx.conf"
        ##
        # SSL Settings
        ##

        ssl_protocols TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE
```
To disable the weak protocols, simply delete  TLSv1 and TLSv1.1 protocols and append TLSv1.2 &  TLSv1.3 at the end.